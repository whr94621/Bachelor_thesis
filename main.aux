\relax 
\citation{harris1954distributional}
\citation{manning2008introduction}
\citation{tellex2003quantitative}
\citation{turian2010word}
\citation{socher2011parsing}
\citation{lund1996producing}
\citation{lebret2013word}
\@writefile{toc}{\contentsline {section}{\numberline {1}基本介绍}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}什么是词嵌入}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}之前的工作}{1}}
\citation{bengio2006neural}
\citation{mikolov2013efficient}
\citation{pennington2014glove}
\citation{shazeer2016swivel}
\citation{levy2014neural}
\citation{levy2015improving}
\citation{vilnis2014word}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces CBOW模型和skip-gram模型的大致框架\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:w2v}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}本文的工作}{3}}
\newlabel{SC@1}{{1.3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 词分布的示意图。这里选取的是选择高斯分布对词进行表示的情况。本图表现出了这种表示的两个特点：具有相近词义的分布的均值比较接近；词频较大和词义较宽泛的协方差较大。\relax }}{4}}
\newlabel{fig:w2d}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Main part}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Theory}{4}}
\citation{gomez2003survey}
\citation{nadarajah2005convolutions}
\citation{jebara2004probability}
\citation{jordan2003introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Word Representation Learning}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Train}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}experiment}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Hyper-Hypo Learning}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 上下位词的两个例子\relax }}{9}}
\newlabel{fig:hyper}{{3}{9}}
\citation{he2015learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Experiment Implementation}{11}}
\bibstyle{plain}
\bibdata{MyBib}
\bibcite{bengio2006neural}{1}
\bibcite{gomez2003survey}{2}
\bibcite{harris1954distributional}{3}
\bibcite{he2015learning}{4}
\bibcite{jebara2004probability}{5}
\bibcite{jordan2003introduction}{6}
\bibcite{lebret2013word}{7}
\bibcite{levy2014neural}{8}
\bibcite{levy2015improving}{9}
\bibcite{lund1996producing}{10}
\bibcite{manning2008introduction}{11}
\bibcite{mikolov2013efficient}{12}
\bibcite{nadarajah2005convolutions}{13}
\bibcite{pennington2014glove}{14}
\bibcite{shazeer2016swivel}{15}
\bibcite{socher2011parsing}{16}
\bibcite{tellex2003quantitative}{17}
\bibcite{turian2010word}{18}
\bibcite{vilnis2014word}{19}
